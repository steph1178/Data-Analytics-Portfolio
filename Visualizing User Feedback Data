import pandas as pd
import nltk
import string
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from collections import Counter
import numpy as np
import matplotlib.pyplot as plt
from wordcloud import WordCloud

%matplotlib inline

userFeedback = pd.read_csv('/Users/stephanie.pandolph/Desktop/Buying Habits Survey.csv')

#check data types:
#userFeedback.dtypes

#use for loop to fill all null values
for col in userFeedback:
    if type(userFeedback[col])== 'object':
        userFeedback[col] = userFeedback[col].fillna(value='unknown')
    else:
        userFeedback[col] = userFeedback[col].fillna(value=0)

#check for any leftover nulls:
#userFeedback.isnull().sum().sum()

#cleanup and rename columns and convert feedback to string

userFeedback.columns = [x.lower() for x in 
                        userFeedback.columns.str.replace(" ","_").str.replace("[:?]","")]
#check the column names and update the rename section below
#userFeedback.head()
userFeedback.rename(columns = {'if_no,_please_explain_why':'q2_reason'}, inplace=True)
userFeedback['q2_reason'] = userFeedback['q2_reason'].astype(str)
userFeedback = userFeedback[["q2_reason"]]
userFeedback['q2_reason'] = userFeedback['q2_reason'].str.replace(r'[^\w\s]+', '')
userFeedback['q2_reason'] = userFeedback['q2_reason'].str.lower()

#tokenize feedback

tokens = [ nltk.word_tokenize( str(sentence) ) for sentence in userFeedback['q2_reason'] ]

#flatten sublists
flattened_tokens = [val for sublist in tokens for val in sublist]



# # #remove stop words
  
stopwords = nltk.corpus.stopwords.words('english')
newStopWords = ['text','see','feel','would','want','prefer']
stopwords.extend(newStopWords)
  
stopwords_removed = [w for w in flattened_tokens if not w in stopwords] 
  
stopwords_removed = [] 
  
for w in flattened_tokens: 
    if w not in stopwords: 
        stopwords_removed.append(w) 

#lemmatize
lemmatizer = WordNetLemmatizer()

lemmatized_words = [lemmatizer.lemmatize(w) for w in stopwords_removed]

#remove characters added by nltk and empty values

reviews_clean = []
for w in lemmatized_words:
    reviews_clean.append(w.replace(']', '',).replace('[','').replace('0','').replace('\"','').replace("\'",'')) 
reviews = list(filter(None, reviews_clean)) 


#word count frequency top ten
counts = Counter(reviews).most_common(10)

#create a wordcloud
wordcloud = WordCloud(
    background_color ='white',
    max_words = 100,
    max_font_size = 40).generate(str(' '.join(reviews)))

    
fig = plt.figure(1, figsize =(20, 20))
plt.axis("off")
       
plt.imshow(wordcloud)
plt.show()


# convert list to DF and Plot horizontal bar using matplotlib bar().

userReviews = pd.DataFrame(counts,
                          columns = ['words','count'])

fig,ax = plt.subplots(figsize=(8,8))

userReviews.sort_values(by='count').plot.barh(x = 'words',
                                           y = 'count',
                                           ax=ax,
                                           color = 'purple')
ax.set_title("Most common words in NPS feedback")

plt.show()
